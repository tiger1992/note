
1、一个查询的动作又是由很多个环节组成的，每个环节都会消耗时间

2、连接 —— 配置优化

  1)、从服务端来说，我们可以增加服务端的可用连接数
  【show variables like 'max_connections';】 -- 修改最大连接数，当有多个应用连接的时候
  及时释放不活动的连接。交互式和非交互式的客户端的默认超时时间都是 28800 秒，8 小时，我们可以把这个值调小
  【show global variables like 'wait_timeout';】 --及时释放不活动的连接，注意不要释放连接池还在使用的连接
  
  2)、引入连接池，实现连接的重用，阿里的 Druid、Spring Boot 2.x 版本默认的连接池 Hikari、老牌的 DBCP 和 C3P0）
  连接数=（（core_count * 2）+ Effective_spindle_count）
  只要维护一定数量大小的连接池，其他的客户端排队等待获取连接就可以了。有的时候连接池越大，效率反而越低。Druid 的默认最大连接池大小是 8。Hikari 的默认最大连接池大小是 10。机器核数乘以 2 加 1。也就是说，4 核的机器，连接池维护 9 个连接就够了
  当我们查看数据库的主要瓶颈时，它们可以概括为三个基本类别：CPU，Disk，Network。我们可以在其中添加内存，但是与磁盘和网络相比，带宽存在几个数量级的差异。
  只有在阻塞为执行创造机会时，更多的线程才能更好地执行
  
3、缓存 —— 架构优化，运行独立的缓存服务，属于架构层面的优化

4、主从 复制 —— 数据库的集群

  1)、用到复制技术（replication），被复制的节点称为 master，复制的节点称为 slave。slave 本身也可以作为其他节点的数据来源，这个叫做级联复制
  
  2)、主从复制是怎么实现的呢？更新语句会记录 binlog，它是一种逻辑日志。有了这个 binlog，从服务器会获取主服务器的 binlog 文件，然后解析里面的 SQL语句，在从服务器上面执行一遍，保持主从的数据一致。
  
  3)、读写分离把数据写入 master 节点，而读的请求可以分担到slave 节点
  
  4)、异步复制：MySQL 默认是异步复制的。也就是说，对于主节点来说，写入 binlog，事务结束，就返回给客户端了。对于 slave 来说，接收到 binlog，就完事儿了，master 不关心 slave 的数据有没有写入成功
  
  5)、全同步复制：等待全部从库的事务执行完毕，才返回给客户端呢？这样的方式叫做全同步复制。从库写完数据，主库才返会给客户端，但会导致 master 节点性能下降
  
  6)、半同步复制：主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到 binlog 并写到 relay log 中才返回给客户端。master 不会等待很长的时间，但是返回给客户端的时候，数据就即将写入成功了，因为它只剩最后一步了：就是读取 relay log，写入从库。
  1.如果我们要在数据库里面用半同步复制，必须安装一个插件，这个是谷歌的一位工程师贡献的。这个插件在 mysql 的插件目录下已经有提供：【cd /usr/lib64/mysql/plugin/】
  2.主库和从库是不同的插件，安装之后需要启用：
  -- 主库执行
  【INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';】
  【set global rpl_semi_sync_master_enabled=1;】
  【show variables like '%semi_sync%';】
  -- 从库执行
  【INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';】
  【set global rpl_semi_sync_slave_enabled=1;】
  【show global variables like '%semi%';】
  注意：最好在低延时的网络中使用
  
  7)、基于 GTID 的复制，修改配置参数打开它，默认是关闭的：【show global variables like 'gtid_mode';】
  
5、分库分表，按日期分表，按业务分库

  1)、垂直分库，减少并发压力。水平分表，解决存储瓶颈。把一个数据库按照业务拆分成不同的数据库：
  
  2)、水平分库分表的做法，把单张表的数据按照一定的规则分布到多个数据库
  
6、解析器：词法和语法分析，主要保证语句的正确性，语句不出错就没问题。由 Sever自己处理，跳过

7、优化器：

  1)、慢查询志 日志 w slow y query log，因为开启慢查询日志是有代价的（跟 bin log、optimizer-trace 一样）
  1.默认是关闭的：【show variables like 'slow_query%';】
  2.除了这个开关，还有一个参数，控制执行超过多长时间的 SQL 才记录到慢日志，默认是 10 秒【show variables like '%long_query_time%';】
  3.可以直接动态修改参数（重启后失效）
  【set @@global.slow_query_log=1;】 -- 1 开启，0 关闭，重启后失效
  【set @@global.long_query_time=3;】 -- mysql 默认的慢查询时间是 10 秒，另开一个窗口后才会查到最新值
  4.或者修改配置文件 my.cnf
  【slow_query_log = ON】
  【long_query_time=2】
  【slow_query_log_file =/var/lib/mysql/localhost-slow.log】
  
8、 存储引擎，存储 引擎的选择，为不同的业务表选择不同的存储引擎，例如：查询插入操作多的业务表，用 MyISAM。临时数据用 Memeroy。常规的并发大更新多的表用 InnoDB。

9、字段定义：原则：使用可以正确存储数据的最小数据类型。为每一列选择合适的字段类型

10、字符类型：变长情况下，varchar 更节省空间，但是对于 varchar 字段，需要一个字节来记录长度。定长度的用 char，不要用 varchar

11、非空：非空字段尽量定义成 NOT NULL，提供默认值，或者使用特殊值、空串代替 null。NULL 类型的存储、优化、使用都会存在问题

12、不要用外键、触发器、视图、存储过程

  1)、降低了可读性
  
  2)、影响数据库性能，应该把把计算的事情交给程序，数据库专心做存储
  
  3)、数据的完整性应该在程序中检查
  
13、大文件存储：不要用数据库存储图片（比如 base64 编码）或者大文件；把文件放在 NAS 上，数据库只需要存储 URI（相对路径），在应用中配置 NAS 服务器地址。

14、表拆分：将不常用的字段拆分出去，避免列数过多和数据量过大。比如在业务系统中，要记录所有接收和发送的消息，这个消息是 XML 格式的，用blob 或者 text 存储，用来追踪和判断重复，可以建立一张表专门用来存储报文。



除了对于代码、SQL 语句、表定义、架构、配置优化之外，业务层面的优化也不能
忽视。举几个例子：

  1）在某一年的双十一，为什么会做一个充值到余额宝和余额有奖金的活动（充 300送 50）？
  因为使用余额或者余额宝付款是记录本地或者内部数据库，而使用银行卡付款，需要调用接口，操作内部数据库肯定更快。
  
  2）在去年的双十一，为什么在凌晨禁止查询今天之外的账单？
  这是一种降级措施，用来保证当前最核心的业务。
  
  3）最近几年的双十一，为什么提前一个多星期就已经有双十一当天的价格了？
  预售分流。
  
  在应用层面同样有很多其他的方案来优化，达到尽量减轻数据库的压力的目的，比如限流，或者引入 MQ 削峰，等等等等。
  为什么同样用 MySQL，有的公司可以扛住百万千万级别的并发，而有的公司几百个并发都扛不住，关键在于怎么用。所以，用数据库慢，不代表数据库本身慢，有的时候还要往上层去优化。
  
  当然，如果关系型数据库解决不了的问题，我们可能需要用到搜索引擎或者大数据的方案了，并不是所有的数据都要放到关系型数据库存储
  
  
  
  
  
  
  
  
  
  
  

